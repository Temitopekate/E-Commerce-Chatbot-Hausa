{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf1f7ba",
   "metadata": {},
   "source": [
    "##### Detect Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "sentence = \"Me yake wannan abu?\"\n",
    "detected_language = detect(sentence)\n",
    "\n",
    "print(f\"The detected language is: {detected_language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "\n",
    "sentence = \"Me yake wannan abu?\"\n",
    "detected_language, confidence = langid.classify(sentence)\n",
    "\n",
    "# Check if the detected language is Hausa with a certain confidence threshold\n",
    "if detected_language == 'ha' and confidence > 0.5:\n",
    "    print(\"The detected language is Hausa.\")\n",
    "else:\n",
    "    print(\"The detected language is not Hausa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12bb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "978d9641",
   "metadata": {},
   "source": [
    "##### Translate sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b108e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: Sannu, ta yaya zan iya taimaka muku?\n",
      "Translated Sentence: Hello, how can I help you?\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def translate_to_english(sentence, source_language='auto', target_language='en'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(sentence, src=source_language, dest=target_language)\n",
    "    return translation.text\n",
    "\n",
    "# Example usage:\n",
    "sentence_to_translate = \"Sannu, ta yaya zan iya taimaka muku?\"\n",
    "translated_sentence = translate_to_english(sentence_to_translate, source_language='ha')\n",
    "\n",
    "print(f\"Original Sentence: {sentence_to_translate}\")\n",
    "print(f\"Translated Sentence: {translated_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ce92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def translate_to_english(sentence, source_language='auto', target_language='en'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(sentence, src=source_language, dest=target_language)\n",
    "    return translation.text\n",
    "\n",
    "def translate_to_hausa(text, source_language='en', target_language='ha'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src=source_language, dest=target_language)\n",
    "    return translation.text\n",
    "\n",
    "# Call function for Hausa to English\n",
    "sentence_to_translate = input(\"Enter a text to translate: \")\n",
    "translated_sentence = translate_to_english(sentence_to_translate, source_language='ha')\n",
    "\n",
    "print(f\"Original Sentence: {sentence_to_translate}\")\n",
    "print(f\"Translated Sentence: {translated_sentence}\")\n",
    "\n",
    "# Call function for English to Hausa\n",
    "text_to_translate = \"Hello, how are you?\"\n",
    "translated_text = translate_to_hausa(text_to_translate, source_language='en', target_language='ha')\n",
    "\n",
    "print(f\"Original Text: {text_to_translate}\")\n",
    "print(f\"Translated Text: {translated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415578f",
   "metadata": {},
   "source": [
    "##### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277ce5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how can I help you?\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "translated_sentence\n",
    "\n",
    "print(translated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cedb85eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization: ['Hello', ',', 'how', 'can', 'I', 'help', 'you', '?']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = translated_sentence\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Assuming you have a tokenizer with word_index (replace this with your actual tokenizer)\n",
    "tokenizer = nltk.FreqDist(tokens)\n",
    "tokenizer.word_index = {word: idx for idx, (word, _) in enumerate(tokenizer.items(), 1)}\n",
    "\n",
    "# Translate tokens to indices\n",
    "tokenized_sentence = []\n",
    "for token in tokens:\n",
    "    if token in tokenizer.word_index:\n",
    "        tokenized_sentence.append(tokenizer.word_index[token])\n",
    "    else:\n",
    "        tokenized_sentence.append(0)\n",
    "\n",
    "print(\"Tokenization:\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f8c3b",
   "metadata": {},
   "source": [
    "##### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b55e2f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['Hello', ',', 'how', 'can', 'I', 'help', 'you', '?']\n",
      "Stemmed Tokens: ['hello', ',', 'how', 'can', 'i', 'help', 'you', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Apply Porter stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# Print the original and stemmed tokens\n",
    "print(\"Original Tokens:\", tokens)\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d1a68",
   "metadata": {},
   "source": [
    "##### Entities Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "184988a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: Hello, how can I help you?\n",
      "POS Tags: [('Hello', 'NNP'), (',', ','), ('how', 'WRB'), ('can', 'MD'), ('I', 'PRP'), ('help', 'VB'), ('you', 'PRP'), ('?', '.')]\n",
      "Extracted Entities: ['Hello']\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "# Perform Named Entity Recognition (NER)\n",
    "ner_result = ne_chunk(pos_tags)\n",
    "\n",
    "# Extract entities from the NER result\n",
    "entities = []\n",
    "for entity in ner_result:\n",
    "    if isinstance(entity, nltk.Tree):\n",
    "        entities.append(\" \".join([word for word, tag in entity.leaves()]))\n",
    "\n",
    "# Print the original sentence, POS tags, and extracted entities\n",
    "print(\"Original Sentence:\", sentence)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "print(\"Extracted Entities:\", entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
